import re
import string
import nltk
nltk.download('punkt')
nltk.download('stopwords')
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

f = open('test.txt', 'r').read()
tok = word_tokenize(f)

print("Enter a choice to process your text:")
print("1: Lowercase")
print("2: Uppercase")
print("3: Tokenize")
print("4: Remove numbers")
print("5: Remove punctuation")
print("6: Remove spaces")
print("7: Remove stopwords")

while True:
    c = int(input())
    if c == 1:
        print(f.lower())
    elif c == 2:
        print(f.upper())
    elif c == 3:
        print(tok)
    elif c == 4:
        print(re.sub(r'[0-9]', '', f))
    elif c == 5:
        print(f.translate(str.maketrans('', '', string.punctuation)))
    elif c == 6:
        print(f.replace(" ", ""))
    elif c == 7:
        print([i for i in tok if i not in set(stopwords.words('english'))])
    else:
        print("Please enter a choice between 1 and 7")
